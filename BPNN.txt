from __future__ import print_function
import numpy as np
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import RMSprop, Adadelta, Adagrad, Adam, Nadam, SGD
from keras.callbacks import EarlyStopping, TerminateOnNaN
from keras.models import load_model
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.metrics import r2_score
import datetime
import xlsxwriter


def __get_data__(name, sheet, column):
    total_file = pd.read_excel('C:\\Users\\70473\\Desktop\\test4_correct\\' + name + '.xlsx', sheet_name=sheet)
    used_data = total_file.loc[:, column]
    used_data0 = np.array(used_data)
    data = used_data0[1:, :]
    print(name + ' Data extraction complete')
    return data


def stand(a, b):
    a = a.astype(float)
    max1 = a.max()
    min1 = a.min()
    range1 = max1 - min1
    if range1 == 0 and b == 0:
        return [0] * len(a)
    else:
        for ii in range(len(a)):
            a[ii] = (a[ii] - min1) / range1
        if b == 0:
            return a
        elif b == 1:
            return range1
        else:
            return min1

def inv_stand(a, range1, min1):
    a = a.astype(float)
    for ii in range(len(a)):
        a[ii] = a[ii] * range1 + min1
    return a


def val_stand(a, range1, min1):
    if range1 == 0:
        return [0] * len(a)
    else:
        for ii in range(len(a)):
            a[ii] = (a[ii] - min1) / range1
        return a


def __time_str__():
    curr_time = datetime.datetime.now()
    time_str = datetime.datetime.strftime(curr_time, '%Y-%m-%d %H-%M-%S')
    return time_str


def bpnn(input_d, output_d, tr_size, n_layers, n_nodes, drop_frac, optimizer_val, optimizer_name, range0, min0, input_v,
         output_v, name):
    batch_size = 100
    num_epochs = 50
    val_frac = 0.1
    patience_val = 30

    trainX, trainY = input_d[:tr_size, :], output_d[:tr_size]
    testX, testY = input_d[tr_size:, :], output_d[tr_size:]

    model = Sequential()
    for layer in np.arange(n_layers):
        if layer == 0:
            model.add(Dense(n_nodes, activation='selu',
                            input_shape=(np.shape(trainX)[1],)))
        else:
            model.add(Dense(n_nodes, activation='selu'))
        model.add(Dropout(drop_frac))
    model.add(Dense(1, activation='selu'))

    model.compile(loss='mean_squared_error',
                  optimizer=optimizer_val,
                  metrics=['accuracy'])
    early_stopping = EarlyStopping(monitor='val_loss', patience=patience_val, verbose=1)

    history = model.fit(trainX, trainY,
                        batch_size=batch_size,
                        epochs=num_epochs,
                        verbose=1,
                        validation_split=val_frac, callbacks=[early_stopping, TerminateOnNaN()])

    test_score = model.evaluate(testX, testY)

    pre_output = model.predict(testX, batch_size=batch_size)
    testY2 = []
    pre_output2 = []
    for t in range(len(testY)):
        testY2.append(testY[t])
        pre_output2.append(pre_output[t][0])

    pre_output_inv = inv_stand(pre_output, range0[0], min0[0])
    testY_inv = inv_stand(testY, range0[0], min0[0])

    pre_output3 = np.array(pre_output2)
    testY3 = np.array(testY2)
    pre_output2_inv = inv_stand(pre_output3, range0[0], min0[0])
    testY2_inv = inv_stand(testY3, range0[0], min0[0])

    for p in range(len(pre_output)):
        if pre_output[p][0] < 0:
            pre_output[p][0] = 0

    for p in range(len(pre_output2)):
        if pre_output2[p] < 0:
            pre_output2[p] = 0

    for p in range(len(pre_output_inv)):
        if pre_output_inv[p] < 0:
            pre_output_inv[p] = 0

    r2_pre = r2_score(testY, pre_output)
    r2_pre2 = r2_score(testY2, pre_output2)
    print('R2_1 = ', r2_pre, 'R2_2 = ', r2_pre2)

    acc = history.history['accuracy']
    val_acc = history.history['val_accuracy']
    loss = history.history['loss']
    val_loss = history.history['val_loss']

    plt.subplot(2, 1, 1)
    plt.plot(acc, label='Training Accuracy')
    plt.plot(val_acc, label='Validation Accuracy')
    plt.legend()

    plt.subplot(2, 1, 2)
    plt.plot(loss, label='Training Loss')
    plt.plot(val_loss, label='Validation Loss')
    plt.legend()
    plt.suptitle(name + ', layers=' + str(n_layers) + ', nodes=' + str(n_nodes))
    plt.show()


    pre_output_v = model.predict(input_v, batch_size=batch_size)
    r2_pre_v = r2_score(output_v, pre_output_v)
    print('R2_v = ', r2_pre_v)
    pre_output_v_inv = inv_stand(pre_output_v, range0[0], min0[0])
    output_v_inv = inv_stand(output_v, range0[0], min0[0])
    for p in range(len(pre_output_v_inv)):
        if pre_output_v_inv[p] < 0:
            pre_output_v_inv[p] = 0

    return pre_output_v_inv, output_v_inv


def __data_write__(datas):
    ti = __time_str__()
    file = xlsxwriter.Workbook("C:\\Users\\70473\\Desktop\\JT run\\Machine Learning result\\BPNN" + ti + ".xlsx")
    sheet1 = file.add_worksheet()
    jj = 0
    for ii in range(datas.shape[0]):
        sheet1.write(ii, jj, datas[ii])
    file.close()


used_column = ['wd', '30minR', '1hR', 'amountR', 'ele-tide']
ngb_train_data = __get_data__('内港北total_from21.6.1except21.6.28', 'Sheet1', used_column)
ngb_vali_data = __get_data__('内港北21.6.28', '21.6.28', used_column)
ng_train_data = __get_data__('内港total', 'Sheet1', used_column)
ng_vali_data = __get_data__('内港21.6.28', '21.6.28', used_column)
kgm_train_data = __get_data__('康公庙total', 'Sheet1', used_column)
kgm_vali_data = __get_data__('康公庙21.6.28', '21.6.28', used_column)
sdk_train_data = __get_data__('司打口total', 'Sheet1', used_column)
sdk_vali_data = __get_data__('司打口21.6.28', '21.6.28', used_column)
xhj_train_data = __get_data__('下环街total', 'Sheet1', used_column)
xhj_vali_data = __get_data__('下环街21.6.28', '21.6.28', used_column)
ngn_train_data = __get_data__('内港南total', 'Sheet1', used_column)
ngn_vali_data = __get_data__('内港南21.6.28', '21.6.28', used_column)

pre_all_station = np.array(())
act_all_station = np.array(())

for loop in range(6):
    if loop == 0:
        data_array0 = ngb_train_data
        vali_data0 = ngb_vali_data
        station_name = 'ngb'
    elif loop == 1:
        data_array0 = ng_train_data
        vali_data0 = ng_vali_data
        station_name = 'ng'
    elif loop == 2:
        data_array0 = kgm_train_data
        vali_data0 = kgm_vali_data
        station_name = 'kgm'
    elif loop == 3:
        data_array0 = sdk_train_data
        vali_data0 = sdk_vali_data
        station_name = 'sdk'
    elif loop == 4:
        data_array0 = xhj_train_data
        vali_data0 = xhj_vali_data
        station_name = 'xhj'
    else:
        data_array0 = ngn_train_data
        vali_data0 = ngn_vali_data
        station_name = 'ngn'

    col = data_array0.shape[1]
    hor = data_array0.shape[0]
    data_array = data_array0.astype(float)
    range0 = [0] * col
    min0 = [0] * col
    max0 = [0] * col

    for i in range(data_array0.shape[1]):
        max0[i] = max(data_array0[:, i])
        min0[i] = min(data_array0[:, i])
        range0[i] = max0[i] - min0[i]
        data_array[:, i] = stand(data_array0[:, i], 0)

    vali_data = vali_data0[1:, :].astype(float)
    for i in range(vali_data.shape[1]):
        vali_data[:, i] = val_stand(vali_data[:, i], range0[i], min0[i])
    v_output = vali_data[:, 0]
    v_input = vali_data[:, 1:]
    v_length = len(vali_data)

    optimizer_names = ['Adagrad', 'Adadelta', 'Adam', 'Nadam', 'RMSprop', 'SGD', 'NSGD']
    optimizer_vals = [Adagrad(clipnorm=1), Adadelta(clipnorm=1), Adam(clipnorm=1), Nadam(clipnorm=1),
                      RMSprop(clipnorm=1), SGD(clipnorm=1.), SGD(clipnorm=1, nesterov=True)]

    optimizer_num = 3  # Adam
    optimizer_name = optimizer_names[optimizer_num]
    optimizer_val = optimizer_vals[optimizer_num]

    drop_frac = 0  # Fraction of nodes to be dropped out
    n_layers = 3  # Number of hidden layers
    n_nodes = (len(used_column)-1) * 2 + 3
    tr_size = round(hor * 0.70)

    circulation = 1
    prediction_all = np.array(())
    actual_all = np.array(())
    prediction = np.array(())
    actual = np.array(())
    for i in range(circulation):
        index = [i for i in range(len(data_array))]
        np.random.shuffle(index)
        data_array_random = data_array[index]

        output_data = data_array_random[:, 0]
        input_data = data_array_random[:, 1:]

        prediction, actual = bpnn(input_data, output_data, tr_size, n_layers, n_nodes, drop_frac,
                          optimizer_val, optimizer_name, range0, min0, v_input, v_output, station_name)
        actual2 = actual.reshape(v_length, 1)
        if i == 0:
            prediction_all = prediction
            actual_all = actual2
        else:
            prediction_all = np.hstack([prediction_all, prediction])
            actual_all = np.hstack([actual_all, actual2])

    pre_value = np.mean(prediction_all, axis=1)
    act_value = np.mean(actual_all, axis=1)
    __data_write__(pre_value)
    r2_final = r2_score(act_value, pre_value)
    x1 = range(len(act_value))
    plt.plot(x1, act_value, 'r')
    plt.plot(x1, pre_value, 'b')
    plt.title(station_name + ' (Average), R2=' + str(r2_final))
    plt.show()
    if loop == 0:
        pre_all_station = pre_value
        act_all_station = act_value
    else:
        pre_all_station = np.hstack([pre_all_station, pre_value])
        act_all_station = np.hstack([act_all_station, act_value])

    print("Next")

r2_final_all = r2_score(act_all_station, pre_all_station)
x1 = range(len(act_all_station))
plt.plot(x1, act_all_station, 'r')
plt.plot(x1, pre_all_station, 'b')
plt.title('All in Average, R2=' + str(r2_final_all))
plt.show()
